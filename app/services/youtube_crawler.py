from youtube_comment_downloader import YoutubeCommentDownloader
from pymongo import MongoClient
from datetime import datetime, timezone
import requests

from app.core.config import settings

API_KEY = settings.youtube_api_key

# MongoDB ì—°ê²°
client = MongoClient(settings.mongo_uri)
db = client["kickon"]
collection = db["youtube_comments"]

# ì˜ìƒ ê²€ìƒ‰ (ì—…ë¡œë“œì¼ ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§)
def search_videos(query, max_results=10):
    search_url = "https://www.googleapis.com/youtube/v3/search"
    params = {
        "part": "snippet",
        "q": query,
        "type": "video",
        "maxResults": max_results,
        "order": "relevance", # ê´€ë ¨ë„ ì¤‘ì‹¬
        "key": API_KEY
    }
    response = requests.get(search_url, params=params)
    response.raise_for_status()
    items = response.json()["items"]

    # í•„í„°: ê²€ìƒ‰ì–´ì˜ ì–‘ìª½ íŒ€ ì´ë¦„ì´ ëª¨ë‘ ì œëª©ì— ë“¤ì–´ê°„ ê²½ìš°ë§Œ í†µê³¼
    teams = [part.strip() for part in query.replace("í•˜ì´ë¼ì´íŠ¸", "").split("vs") if part.strip()]
    
    filtered_items = []
    for item in items:
        title = item["snippet"]["title"].lower()
        if all(team.lower() in title for team in teams):
            filtered_items.append(item)
    
    return [
        {
            "video_id": item["id"]["videoId"],
            "title": item["snippet"]["title"],
            "published_at": item["snippet"]["publishedAt"]
        }
        for item in filtered_items
    ]

# ëŒ“ê¸€ í¬ë¡¤ë§ ë° ì €ì¥
def crawl_and_store_comments_by_query(query):
    print(f"\nğŸ” [1] ê²€ìƒ‰ ì¿¼ë¦¬: {query}")

    try:
        videos = search_videos(query)
        print(f"ğŸ“º [2] ê²€ìƒ‰ëœ ì˜ìƒ ìˆ˜: {len(videos)}")
    except Exception as e:
        print(f"âŒ ìœ íŠœë¸Œ ê²€ìƒ‰ ì¤‘ ë¬¸ì œ ë°œìƒ: {e}")
        return
    
    for video in videos:
        video_id = video["video_id"]
        print(f"\nğŸ¬ [3] ì˜ìƒ ì œëª©: {video['title']} / ID: {video_id}")

        # ì´ë¯¸ í¬ë¡¤ë§í•œ ì˜ìƒì¸ì§€ í™•ì¸
        if collection.find_one({"video_id": video_id}):
            print(f"â© ì´ë¯¸ í¬ë¡¤ë§í•œ ì˜ìƒì…ë‹ˆë‹¤: {video['title']}")
            continue

        downloader = YoutubeCommentDownloader()
        video_url = f"https://www.youtube.com/watch?v={video_id}"

        comment_data = []

        try:
            for comment in downloader.get_comments_from_url(video_url, sort_by=0):
                comment_text = comment["text"]
                comment_obj = {
                    "author": comment.get("author", "unknown"),
                    "text": comment_text,
                    "published_at": datetime.utcnow(),
                    "text_for_embedding": f"ì˜ìƒ ì œëª©: {video['title']}\nëŒ“ê¸€: {comment_text}"
                }
                comment_data.append(comment_obj)
        except Exception as e:
            print(f"âŒ ëŒ“ê¸€ í¬ë¡¤ë§ ì¤‘ ë¬¸ì œ ë°œìƒ: {e}")
            return
        
        print(f"âœ… [4] ëŒ“ê¸€ ìˆ˜ì§‘ ì™„ë£Œ: {len(comment_data)}ê°œ")

        if len(comment_data) == 0:
            print(f"âŒ ëŒ“ê¸€ ì—†ìŒ")
            continue

        doc = {
            "video_id": video_id,
            "video_title": video["title"],
            "video_url": video_url,
            "team_mentioned": query,
            "match_date": None,
            "video_published_at": video["published_at"],
            "crawled_at": datetime.utcnow(),
            "comments": comment_data
        }

        try:
            collection.insert_one(doc)
        except Exception as e:
            print(f"âŒ MongoDB ì €ì¥ ì¤‘ ë¬¸ì œ ë°œìƒ: {e}")